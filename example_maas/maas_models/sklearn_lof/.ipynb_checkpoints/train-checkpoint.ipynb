{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Training Tutorial\n",
    "\n",
    "This `train.pynb` Jupyter notebook is an example for using elastalert with mlflow together.\n",
    "\n",
    "> This is the Jupyter notebook version of the `train.py` example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "ES_URL = \"http://192.168.122.3:9200\"\n",
    "ES_INDEX = \"logs-endpoint-winevent-sysmon-*\"\n",
    "COLUMNS = [\"agent.hostname\", \"event.code\"]\n",
    "MODEL = OneClassSVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch  \n",
    "from elasticsearch_dsl import Search\n",
    "import functools\n",
    "import csv\n",
    "from os.path import isfile as isfile\n",
    "\n",
    "def get_data(elast_url, index, columns):  \n",
    "        \n",
    "        def save_to_csv(elast_url, index, columns, file_name):\n",
    "            \n",
    "            es = Elasticsearch(elast_url,timeout=600)\n",
    "            s = Search(using=es, index=index).query().source(fields=columns)            \n",
    "            \n",
    "            with open(file_name, mode='w') as es_fd:\n",
    "                writer = csv.DictWriter(es_fd, fieldnames=columns)\n",
    "                writer.writeheader()\n",
    "                for hit in s.scan():          \n",
    "            \n",
    "                    # handles nested objects in response because of multilevel keys (i.e. agent.hostname) \n",
    "                    # ac\n",
    "                    def rgetattr(obj, attr):\n",
    "                        def _getattr(obj, attr):\n",
    "                            return getattr(obj, attr)\n",
    "                        return functools.reduce(_getattr, [obj] + attr.split('.'))\n",
    "                    \n",
    "                    hit_dict = {column: rgetattr(hit, column) for column in columns}                    \n",
    "                    writer.writerow(hit_dict)\n",
    "                    \n",
    "        def read_from_csv(csv_file):\n",
    "            data = pd.read_csv(csv_file)\n",
    "            return data\n",
    "                   \n",
    "        file_name = (\n",
    "            str(hash(\"{}{}{}{}{}\"\n",
    "            .format(\n",
    "                len(elast_url),\n",
    "                elast_url,\n",
    "                len(index),\n",
    "                index,\n",
    "                len(columns),\n",
    "                \".\".join(columns))))\n",
    "            + \".csv\"\n",
    "            )\n",
    "        \n",
    "        if not isfile(file_name):\n",
    "            save_to_csv(elast_url,index,columns,file_name)        \n",
    "            \n",
    "        data_frame = read_from_csv(file_name)\n",
    "        \n",
    "        return data_frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.pipeline import Pipeline\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def build_pipeline(data, *params):\n",
    "    np.random.seed(40)   \n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "    numeric_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    categorical_features = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "\n",
    "    # create Model\n",
    "    o_svm = MODEL()\n",
    "\n",
    "    # create pipeline\n",
    "    pipe = Pipeline([('preprocessor', preprocessor),\n",
    "                     ('svc', o_svm)])\n",
    "\n",
    "    return pipe\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def log_output(pipe,data):\n",
    "     \n",
    "        mlflow.sklearn.log_model(pipe, \"model\")\n",
    "        \n",
    "        params = pipe.steps[-1][1].get_params()       \n",
    "        mlflow.log_param(\"model_param\", params)        \n",
    "        \n",
    "        predictions = pipe.predict(data)        \n",
    "        for k,v in Counter(predictions).items():\n",
    "            mlflow.log_metric(\"pred_{}\".format(k), v)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "\n",
    "def train(*params):\n",
    "    \n",
    "    # setup logging\n",
    "    logging.basicConfig(level=logging.WARN)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "    \n",
    "    elast_url = ES_URL\n",
    "    index = ES_INDEX\n",
    "    \n",
    "    data = get_data(elast_url, index, columns= [\"agent.hostname\", \"event.code\"])\n",
    "    data.drop([\"@timestamp\"], axis=1)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        pipe = build_pipeline(data)\n",
    "        pipe.fit(data) \n",
    "        \n",
    "        log_output(pipe,data)\n",
    "        return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['event.code'], dtype='object')),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['agent.hostname', '@timestamp'], dtype='object'))])),\n",
       "                ('svc', OneClassSVM(gamma='auto'))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
